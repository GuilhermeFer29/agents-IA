{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10170/2407517405.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"oi!\")\n",
    "memory.chat_memory.add_ai_message(\"como vai?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: oi!\\nAI: como vai?'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10170/2534319844.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Ola meu nome é Guilherme!\n",
      "AI: Olá Guilherme! Como posso te ajudar hoje?\n",
      "Human: Qualé meu nome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seu nome é Guilherme! Como posso te ajudar hoje?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Qualé meu nome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10170/3391827577.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=1)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hola meu nome é guilherme\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá, Guilherme! Como posso ajudá-lo hoje?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hola meu nome é guilherme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10170/3062267441.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationTokenBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "memory = ConversationTokenBufferMemory( \n",
    "    llm=chat,\n",
    "    max_token_limit=250,)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Resuma a história do livro\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'O livro conta a história de um jovem órfão chamado Harry Potter, que descobre que é um bruxo e é convidado a frequentar a escola de magia e bruxaria de Hogwarts. Lá, ele faz novos amigos, como Hermione Granger e Rony Weasley, e enfrenta desafios como o bruxo das trevas Lord Voldemort. A história aborda temas de amizade, coragem e sacrifício, enquanto Harry luta para superar seu passado e seu destino como O Eleito para derrotar Voldemort.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Resuma a história do livro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10170/1187915657.py:7: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "memory = ConversationSummaryBufferMemory( \n",
    "    llm=chat,\n",
    "    max_token_limit=250,)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Ola meu nome é Guilherme\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Olá Guilherme! É um prazer conhecê-lo. Como posso ajudá-lo hoje?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Ola meu nome é Guilherme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Ola meu nome é Guilherme\n",
      "AI: Olá Guilherme! É um prazer conhecê-lo. Como posso ajudá-lo hoje?\n",
      "Human: Me conte uma historia sobre o universo de 500 palavras\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro, vou adorar compartilhar uma história fascinante sobre o universo com você! Há bilhões de anos, o universo era apenas um ponto minúsculo e denso, contendo toda a matéria e energia do cosmos em uma singularidade infinitesimal. Em um instante, esse ponto minúsculo explodiu em um evento chamado de Big Bang, dando origem ao universo como o conhecemos hoje. A expansão do universo aconteceu rapidamente, com galáxias se formando e se afastando umas das outras em uma dança cósmica.\\n\\nDentro dessas galáxias, estrelas nasceram e morreram, criando elementos químicos essenciais para a vida. Em um desses sistemas estelares, nosso próprio Sistema Solar se formou, com o Sol no centro e planetas orbitando ao seu redor. A Terra, um pequeno ponto azul no vasto cosmos, tornou-se o lar de uma incrível diversidade de formas de vida.\\n\\nAo longo dos milênios, a humanidade olhou para o céu noturno com admiração e curiosidade, buscando compreender o mistério do universo. Astrônomos observaram estrelas, planetas, galáxias e descobriram leis fundamentais que regem o funcionamento do cosmos. Teorias foram desenvolvidas, como a Teoria da Relatividade de Einstein e a Teoria do Big Bang, para explicar a origem e evolução do universo.\\n\\nExplorações espaciais levaram o homem à Lua e além, revelando imagens incríveis de planetas distantes, nebulosas coloridas e buracos negros misteriosos. Missões como a Voyager 1 e 2 continuam a viajar pelo espaço interestelar, levando mensagens da humanidade para quem encontrar no futuro.\\n\\nO universo é vasto e misterioso, cheio de segredos ainda não revelados. Com telescópios cada vez mais poderosos e tecnologias avançadas, os cientistas continuam a desvendar os mistérios do cosmos, explorando buracos negros, matéria escura e a possibilidade de vida em outros planetas.\\n\\nNossa jornada pelo universo é uma busca eterna por conhecimento e compreensão, uma tentativa de decifrar os segredos do cosmos e nosso lugar nele. Enquanto olhamos para as estrelas, somos lembrados de nossa humildade diante da vastidão do universo, mas também de nossa capacidade de explorar, descobrir e sonhar. O universo é um lugar de maravilhas, esperando para ser explorado e compreendido, e nós, como seres humanos, somos parte integrante desse incrível tecido cósmico.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Me conte uma historia sobre o universo de 500 palavras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human introduces themselves as Guilherme and asks the AI to tell a 500-word story about the universe. The AI shares a fascinating story about the universe, starting from the Big Bang and the formation of galaxies to the birth of our Solar System and the exploration of space by humanity. The story highlights the incredible diversity of the cosmos and our eternal quest for knowledge and understanding.\n",
      "Human: Qual é meu nome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Seu nome é Guilherme.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Qual é meu nome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human introduces themselves as Guilherme and asks the AI to tell a 500-word story about the universe. The AI shares a fascinating story about the universe, starting from the Big Bang and the formation of galaxies to the birth of our Solar System and the exploration of space by humanity. The story highlights the incredible diversity of the cosmos and our eternal quest for knowledge and understanding.\n",
      "Human: Qual é meu nome?\n",
      "AI: Seu nome é Guilherme.\n",
      "Human: Oque eu pedi para voce fazer inicialmente?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Você me pediu para contar uma história de 500 palavras sobre o universo.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Oque eu pedi para voce fazer inicialmente?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
